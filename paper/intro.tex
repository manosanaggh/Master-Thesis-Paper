\section{Introduction}
\label{sec:intro}
With the exponential growth of data in various fields such as
healthcare and social media, managed big data frameworks (e.g, Apache
Spark \cite{Spark} and Apache Giraph \cite{Giraph}) require large
amount of DRAM per core for data processing. During the processing, they generate large
amount of objects in the managed heap that span multiple computation
stages. The memory pressure that arises in the managed heap leads to
frequent garbage collection (GC) cycles. Frequent GCs waste CPU cycles 
and prevent application execution.

On the one hand, to reduce the frequency of GC and optimize performance, big data
frameworks offload objects from the managed heap to storage devices. However, these
objects need to be serialized to byte streams to be stored in the storage
device or to be deserialized into memory objects to be loaded back to memory. 
This practice leads to high serialization/deserialization overhead.
On the other hand infrastructure providers, trying to address the same problem increase memory per framework instance that runs in the server. This leaves CPU cores underutilized. 

Co-locating workloads aims to increase available resource utilization
thus increasing the throughput in server. 
In order to maximize throughput, the number of instances
increase to utilize all available DRAM. The result of this
practice is that the underlying machine runs out of memory, while the
 overhead of GC and S/D is still high. The remaining GC and S/D
overheads lead to the problem of wasting the CPU resources
to do unuseful work. This leads to the conclusion that the avalaible memory per core is
not enough for the Garbage Collector, S/D and the application.

The memory per core problem can better be understood when looking at
the resource usage and the characteristics of the servers of big
companies e.g. Alibaba and Facebook. When looking at the results of
Alibaba's traces analyses (\cite{Alibaba}, \cite{Alibaba1},
\cite{Alibabacolocated}) we see that memory usage is at an average of
80\%, while CPU usage stays at 40\%. This trace clearly shows that
DRAM utilization is high, while the CPU is under-utilized. In
Facebook's Twine presentation \cite{Twine}, they used a cluster of
machines where each machine had 40 cores and 80 GB DRAM. This means
that ratio of GB for memory per core was 2. The same ratio is shown in Facebook's Yosemite
\cite{Yosemite}. This shows that memory
capacity for each core is low while DRAM usage is high compared to the CPU usage. Most of the time many the CPU cores are
going to be idle because a few of them will be enough to carry out the
work.

To address the problem of DRAM capacity limitation, recent work
proposed solutions that extend the managed heaps over local flash
storage devices (e.g., NVMe SSD) or remote memory. On the one hand,
TMO \cite{TMO} offloads cold memory to fast storage devices using
a memory scheduling mechanism. On the other hand, CFM \cite{CFM}
utilizes remote DRAM as swap memory in order to increase total memory capacity
and reduce memory pressure. Of both works, only CFM shows
evaluation against managed big data analytics frameworks. However, this evaluation
includes only one Spark workload and is not focused on analytics.

This thesis provides a methodological analysis of server throughput 
focused on managed big data analytics frameworks.
We investigate the off-heap direction of offloading the objects from the
managed heap to fast storage devices.
Specifically, we use TeraHeap (TH) \cite{TeraHeap}, a secondary managed
memory-mapped heap over an NVMe storage device, which is used to hold
the long lived objects instead of the main managed Java Heap. TeraHeap
1) eliminates Serialization/Deserialization overheads posed by this
kind of frameworks when moving data off-heap to/from fast storage
devices 2) reduces GC pauses drastically over the secondary heap. By
using TeraHeap, we aim to investigate the impact of reducing GC and S/D
to server throughput under workload co-location compared to Native Spark
and Giraph. We divide all the available DRAM
in our machine to 2,4 and 8 even budgets to run the co-located instances.
First we run each instance isolated to analyze performance and be able to study the interference when adding more
co-located instances. We run each individual workload with a different Spark or Giraph instance in a cgroup.
We do this to limit the memory budget for each instance. Memory budget is
the summary of Java Heap, IO Cache (Linux Page Cache) and JVM native memory. We choose
the Java Heap (H1) ratio over the total DRAM budget based on RedHat's decisions
for running containers as a baseline. We also run experiment with more Page Cache (PC) ratio than H1
to investigate Page Cache affection to the performance. We show performance of both Native Spark-Giraph and Spark-Giraph with TH in 3 different
memory per core scenarios, 4 GB per core, which is the current trend and 8 and 16 GB per core 
as possible future trends. We evaluate both offloading techniques by running 2 widely used
managed big data frameworks, Apache Spark and Giraph. We
specificaly run 4 different workloads with Spark with 4 and 8 GB per core.
We run 2 different workloads with Giraph with 8 and 16 GB per core.
We compare TeraHeap with the native Spark and Giraph distributions under workload
co-location and analyze their performance using several metrics like
GC, S/D, I/O and CPU utilization. Finally, we estimate the cost of running these
experiments in public world clusters like Amazon EC2, Google Cloud Platform (GCP)
and Microsoft Azure Cloud to see possible benefits of either of the two techniques.

Our experimental results show that there is indeed a problem with memory per core ratio
for managed big data frameworks.
A solution is to move the managed heap over fast storage devices to avoid both GC and S/D like TeraHeap and Panthera \cite{Panthera}.
Our experimental results show that reducing GC and S/D by offloading the heap to fast storage devices improves effective CPU utlization up to 59\% in CPU cycles for Spark and also leaves place to run more co-located instances in the server for both frameworks.
Finally, we also include a cost estimation to show that reducing GC and S/D could reduce monetary cost by up to 50\% for running big data
analytics, in a world cluster like EC2, GCP or Microsoft Azure Cloud, which are available to
the public.

To summarize, this thesis makes the following contributions: 
\begin{itemize}
    \item{A detailed methodology for running co-located Apache Spark and Giraph
        workloads with or without TeraHeap. 
	We show how to pick the DRAM budget for each co-located instance and how to divide this budget
		for the different memory needs of a group of processes.
		}

    \item{A comprehensive evaluation using the above methodology.
	    We run 4 Spark and 2 Giraph workloads in 3 memory per core scenarios
	    analyzing different aspects of performance like GC, S/D, I/O, average throughput, CPU utilization and CPU cycles. We show the interference impact of running multiple co-located managed big data frameworks workloads and show that reducing GC and S/D increases application throughput and utilizes the CPU in a better and more efficient way for Spark. We also show that decreasing GC and S/D, increases the number of co-located instances that can be executed in the server.}

    \item{A cost estimation of running our experiments in real-world
        cloud platforms like Amazon EC2, Google Cloud Platform and Microsoft
        Azure.}
\end{itemize}

%
\end{itemize}
