\section{Introduction}
\label{sec:intro}

With the exponential growth of data in various fields such as finance,
healthcare, social media, and e-commerce, there is a significant need
for more and more system memory from big data analytics frameworks. 
The memory pressure that arises when using these kind of frameworks leads to
long Garbage Collection cycles performed by the Java Virtual Machine.
This requirement leads to excessive CPU under-utilization, 
leading to performance bottlenecks and slow job completion
times. To address these challenges, researchers have proposed various
techniques to optimize the performance of Big data analytics, including
data partitioning, caching, and resource allocation.

\note{jk: explain why you only focus on the memory limit}
In this paper, we focus on the memory limit problem of servers
becoming an obstacle for further throughput increase by not
allowing applications to utilize the CPU. We conduct an
analysis of the performance of big data analytics using a smart
technique for offloading the heap to fast storage devices.
This offloading technique reduces memory pressure by
moving long-lived objects from the main managed Java
Heap to a fast storage device such as NVMe. By doing that it saves memory for
other more useful tasks, leaving space for more CPU utilization.
Offloading the heap leverages the capabilities of the underlying machine to
create less memory-consuming computation tasks, thereby reducing the
workload on the framework workers. Along with that it maintains effective
per-executor performance under the colocation of multiple executors
required to achieve max throughput.

TMO?

Specifically, in order to investigate the heap offloading to fast storage,
we use TeraHeap, a secondary managed
memory-mapped heap over an NVMe storage device, which is used to hold
the long lived objects instead of the main
managed Java Heap and completely remove any
Serialization/Deserialization and Garbage Collection (GC) cost over
them.

TeraHeap 1) eliminates Serialization/Deserialization overheads posed
by this kind of frameworks when moving data off-heap to/from fast
storage devices 2) eliminates GC pauses over the secondary heap,
therefore significantly minimizing overall GC overhead. By offloading
the managed Java Heap and relaxing computation-intensive tasks, we aim
to reduce the workload on executors, thereby improving their
performance and job throughput. We also explore the trade-offs between
the cost of offloading and the performance gains achieved.

We demonstrate the effectiveness of heap offloading to fast storage using various big
data analytics workloads on a real-world cluster. We
compare TeraHeap with the native Spark distribution and show that
an approach like TeraHeap could be used instead of this distribution to improve
performance and server throughput. \note{Here you should provide some
overall results. Please update this paragraph including Giraph}

The paper makes the following contributions: 
\begin{itemize}
    \item{A comprehensive
        evaluation of the performance and cost trade-offs of our proposed heap
        offloading technique, that utilizes fast storage devices to improve
        server throughput for Big Data Analytics.
    \item{A detailed methodology for running Apache Spark and
        understanding how to use it for conducting off-heap
        experiments using the Native Spark or TeraHeap \note{jk: this
        is similar with the first contirbution.}}
\end{itemize}

\note{jk: Overall. The first two paragraphs of the introduction should
show the problem statement. Then 3rd paragraph should summarize the
limitations of existing work. Next you should show what this paper
does. For exaple about methodology. Why it is important? What
questions are you trying to answer. Then in the next paragraph you
should try to summarize the overall results. Finally add the
contributions of the paper as an itemized list.}
