\section{Related Work}

We group the related work in the two following categories:
\begin{itemize}
\item{Policy systems for instance collocation}
\item{Analyses on managed big data frameworks}
\end{itemize}

\subsection{Scheduling systems for instance collocation}
One approach is to utilize memory-model-based task
co-location during runtime to improve Spark application throughput, which has been
investigated by Marco et al. in \cite{Colocation}. They choose a variety of memory-models
that describe the memory footprint of Spark applications and determine the right memory-model
for the specific application at runtime. That way they learn how many applications can be colocated
to achieve better throughput. However... 

\subsection{Analyses on managed big data frameworks}

Jiang et al. in \cite{inmem} study the behavior of Spark Workloads in comparison to those of Giraph, CloudSuite, SPEC CPU2006,
TPC-C, and DesktopCloud on system and microarchitectural level. However, they do not provide any detailed methodology on how to 
run the workloads, any breakdowns to execution time of the workloads and any collocated experiments. Ousterhout et al. \cite{makingsense} provide a methodology for quantifying performance bottlenecks in distributed computation frameworks, and use it to analyze the Sparkâ€™s performance. The limitations of this work is the evaluation against only 2 SQL workloads. Batarfi et al. \cite{giraphgraphalytics} analyze the performance of many graph processing frameworks including Giraph without any specific methodology and breakdown of the execution. They just use plain metrics and try to understand performance based on them without any further analysis. They also only show results for graph processing and do not target other areas like machine learning. Baig et al. in \cite{NUMA} investigate how Spark-based workloads are impacted by the effects of NUMA-placement decisions and they also evaluate with collocated instances. However they do not show any breakdown of the execution that could provide insights on how GC and S/D are affected by NUMA placement. Furthermore, their work is evaluated only aganst Spark. Ahmed et al. \cite{hibench} investigate the most impacting parameters, under resource utilization, input splits, and shuffle, to compare the performance between Hadoop and Spark, using an implemented cluster in our laboratory. The problem is that they do not provide any detailed methodology, only evaluate against two workloads and fail to provide execution breakdown. Chen et al. in \cite{interference} analyze the characteristics of co-located workloads running in containers on the same server from the perspective of hardware events. Their work lacks on methodology because it provides only a speculation of the performance degradation when workloads are collocated. They also do not evaluate against managed big data frameworks. 

\cite{CoLoc},\cite{SLA}, \cite{Hadoop-based}, \cite{splitserve}
