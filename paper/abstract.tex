\begin{abstract}
    Managed big data frameworks, such as Apache Spark and Giraph
    demand large amount of memory to process massive volume
    datasets effectively. The memory pressure that arises from the big data processing leads to
    long garbage collection (GC). In order to avoid this overhead, big
    data analytics frameworks, increase heap capacity or try offloading objects to storage devices. 
    Increasing heap capacity to optimize performance reduces the number of co-located instances
	that can be executed in order to increase utilization of available resources.
	On the other hand offloading objects to storage devices poses other overheads like Serialization/Deserialization (S/D).
    These limits prevent the frameworks from effectively utilizing the CPU thus
    leading to low server throughput and shows that the memory/core ratio is not enough to both satisfy overheads and the application.

    In this paper, we conduct a methodological analysis of server throughput for
    managed big data analytics frameworks. More specifically, we examine, whether
    reducing GC and S/D	can help increase the effective CPU utilization of the server.
    We use a system called TeraHeap (TH) that moves objects from
	the Java managed heap (H1) to a secondary heap over a fast storage
	device (H2) to reduce the GC overhead and eliminate S/D over data. We focus on analyzing the system's
    performance under the co-location of multiple memory-bound
    instances. Our detailed methodology includes choosing the DRAM budget for each instance and how to distribute
	this budget among H1 and Page Cache (PC). We try two different distributions for the DRAM budget, one with more H1
	and one with more PC to study the needs of both approaches. 
    We evaluate both techniques under 2 different memory/core scenarios using Spark and Giraph with native JVM or JVM with TeraHeap. 
	We report GC, S/D, I/O, average server throughput and CPU utilization.

    Our experimental results show that reducing Java Garbage
    Collection overhead by offloading the heap to fast storage devices
    significantly improves server throughput by up to 77\% against
    native Spark and 13\% against Native Giraph. Finally, we also include a cost
    estimation to show that using an approach like TeraHeap could reduce monetary cost by up
    to 50\% for running big data analytics in a world
    cluster like Amazon's EC2 or Google Cloud Platform or Microsoft
    Azure Cloud, which are available to everyone.
\end{abstract}
