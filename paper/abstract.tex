\begin{abstract}

    Managed big data analytic frameworks require a lot of memory to process
    large amounts of data.
    %
    The memory pressure that arises from Garbage Collction during the data processing,
    prevents the frameworks from effectively utilizing the CPU thus leading to
    low server throughput.
    In this paper, we conduct an analysis of server
    throughput for managed big data analytics. We evaluate a smart technique for heap
    offloading to fast storage devices in order to reduce memory pressure.
    %
    We use a framework called TeraHeap that moves objects from the Java
    managed heap to a secondary heap over a fast storage device. 
    Our primary focus is to examine its performance under the colocation of
    multiple memory-bound instances. 
    %
    Furthermore, we present a detailed methodology for running Apache Spark and Giraph using TeraHeap. 
    The methodology includes conducting a research about the memory needs of Big data analytics when using offheap mechanisms
    i.e. Java Heap and IO Cache. Understanding these needs helps us run the experiments with colocated instances.
    Our experimental results show that reducing memory pressure
    by offloading the heap to fast storage devices
    significantly improves server throughput up to 50\% by reducing
    memory usage against native Spark and Giraph. Finally, we also include
    a cost estimation to show that TeraHeap could reduce monetary cost up to 50\% for running Big data analytics if
    deployed in a world cluster like Amazon's EC2 or Google Cloud
    Platform or Microsoft Azure Cloud which are available to everyone. 
\end{abstract}
