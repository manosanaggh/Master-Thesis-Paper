\begin{abstract}

    Managed big data analytic frameworks require a lot of memory to process
    large amounts of data.
    %
    The memory pressure that arises during the processing of
    large amounts of data
    prevents the frameworks from utilizing the CPU thus leading to
    low server throughput.
    %
    This pressure leads to long Garbage Collection
    (GC) cycles
    leaving no room for useful work. 
    In this paper, we conduct an analysis of server
    throughput for managed big data analytics using smart heap
    offloading to fast storage devices in order to reduce memory pressure.
    %
    We use a framework called TeraHeap that moves objects from the Java
    managed heap to a secondary heap over a fast storage device
    thereby freeing
    up heap memory and reducing memory pressure without suffering from
    storage latencies.  
    %
    By overcoming the memory bound we leave space
    to the applications for more CPU utilization. 
    %
    We present a
    detailed methodology for running Apache Spark and Giraph using TeraHeap, which significantly improves
    server throughput for managed big data analytics. The methodology includes
    conducting a research about the needs of Big data analytics when using offheap mechanisms
    such as the need for Java Heap or for IO Cache, breaking down the execution time and explaining
    every different metric, provinding results such as server throughput...\note{jk: Why
    your methodology is important. What aspects are you investigate.
    You should write here 2-3 sentences trying to show that you put
    effort for the methodology}. TeraHeap is implemented in Oracle's OpenJDK8. In this paper we
    evaluate its performance against Native Spark and Giraph using various
    workloads of the Spark Bench suite and graphalytics library on a real-world cluster.
    Our primary focus is to examine its performance under the colocation of
    multiple instances. 
    Our experimental results show that reducing memory pressure
    by offloading the heap to fast storage devices
    significantly improves server throughput while reducing
    memory usage against native Spark and Giraph. We also include
    results to show that TeraHeap can reduce monetary cost if
    deployed in a world cluster like Amazon's EC2 or Google Cloud
    Platform or Microsoft Azure Cloud which are available to everyone. 
    \note{jk: Overall comments for the abstract. Abstract should be
    maximum 250 - 300 words. Split it in two or three paragraphs.
    First paragraph state the problem. This paragraph should be
    maximum 3-4 sentences. Next paragraph you should explain what this
    paper provides. In our case is the methodology and evaluation.
    Finally, in the third paragraph you should mention the most
    important results. What the author should rembember.}
\end{abstract}
