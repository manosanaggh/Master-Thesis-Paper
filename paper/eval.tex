\section{Evaluation}
\label{sec:eval}

In this section we report and analyze our experiments and we also state our conclusions.

\iffalse
\begin{table}[thbp]
  \centering
  \caption{Server Specifications}
  \label{tab:server-specs}
  \begin{tabular}{|c|c|}
    \hline
    \textbf{Component} & \textbf{Specification} \\
    \hline
    Memory & 8x DDR4 32-GB \\
    CPU & Intel Xeon E5-2630 2.4 GHz \\
    Cores & 16 \\
    L1 Cache & 512 KB \\
    L2 Cache & 2 MB \\
    L3 (LLC) Cache & 20 MB \\
    Storage & 2x 1.8 TB KVS NVMe \\
    \hline
  \end{tabular}
\end{table}

\subsection{Server Characteristics}
Table \ref{tab:server-specs} summarizes the characteristics of our server.
The server used in our experiments is a high-performance machine with
hardware specifications found in real-world clusters.
It is equipped with 8x DDR4 32-GB 2.4 GHz 64-bit DIMMs, providing a
total of 256 GB of memory. The DDR4 memory technology is known for its
high bandwidth and low power consumption, making it ideal for
data-intensive applications like big data analytics. The server also
features Intel Xeon E5-2630 2.4 GHz 64-bit CPU with 16 cores. 
Each core has 512 KB L1, 2 MB L2, and 20 MB L3 (LLC) cache.
The Xeon E5-2630 CPU is a high-performance processor designed for data
centers, offering a high core count, high clock speed, and advanced
features like hyper-threading and Turbo Boost. The large L3 cache
helps reduce memory latency, enabling faster data access for CPU-bound
workloads. In addition to the powerful CPUs and memory, the server
also has 2x KVS NVMe storage devices. NVMe is a high-performance
storage technology that uses PCIe to connect directly to the CPU,
providing low latency and high throughput. The KVS (Key-Value Store)
storage devices are designed for fast, random access to data, making
them ideal for storing and retrieving large amounts of data in big
data applications. Overall, the server's hardware specifications make
it a powerful platform for conducting experiments on managed big data
analytics and evaluating their performance.
\fi
\subsection{Native Spark Configuration}
We use Spark v3.3.0 (\cite{Building}, \cite{Tuning}, \cite{Conf}, \cite{Monitoring}) with Kryo Serializer \cite{Kryo}, a state-of-the-art highly optimized S/D Library for Java that Spark recommends. We run Spark
with Native OpenJDK8 \cite{JDK8} as a baseline. We use the Parallel Scavenge
garbage collector which is the one TeraHeap is implemented for.
Parallel Scavenge is also the go-to collector for applications that
need high throughput like Spark. We use one executor with 8
threads for each instance of Spark we deploy on our server \cite{TeraHeap}. Spark storage level
is configured to MEMORY-AND-DISK to place executor memory (heap) in DRAM and cache RDDs \cite{RDD}
in the on-heap cache, up to 50\% of the total heap size. Any remaining
RDDs are serialized in the off-heap cache over an NVMe SSD. This
device is also used by Spark for shuffling. 

\subsection{Native Giraph Configuration}
We run Giraph with Native OpenJDK8 \cite{JDK8} as a baseline. We use the Parallel Scavenge
garbage collector. We use one executor with 8 threads for each instance of Giraph we deploy on our server \cite{TeraHeap}. Native Giraph offloads messages and edges to the storage device.

\subsection{TeraHeap background and Spark-Giraph configurations for TeraHeap}
\subsubsection{What is TeraHeap?}
TeraHeap is a high-capacity managed heap that is memory-mapped over a
fast storage device (preferrably block-addresable NVMe or
byte-addresable NVM). The high speeds these kind of devices operate
in, erase any overhead caused by the use of MMIO. MMIO keeps the objects that reside in the storage
device deserialized, thus eliminating the need for Serialization/Deserialization  TeraHeap is designed
as an extension of the main Java Heap and is region-based. It holds specific long-lived
objects that have the same lifetime span in specific regions. This enables TeraHeap to
operate as a GC-free heap that can delete entire regions of objects at
once without the need to scan the heap over and over again for dead
objects. This would be a performance kill as it would require scans
over the storage device.

\subsubsection{Spark Configuration}
The configuration for TeraHeap is pretty much the same as for Native
Spark, with some necessary differences. TeraHeap
is mapped to a different storage device (NVMe) than that Spark is
using for shuffling. We do this in order for TeraHeap to utilize its
device to its fullest. MMIO allows TeraHeap Spark to run in
MEMORY-ONLY storage level as Spark remains unaware of using any device and
the OS takes control of the I/O.

\subsubsection{Giraph Configuration}
For Giraph, we map TeraHeap to a different NVMe storage device that the one we
use for Zookeeper. TeraHeap works in the same way as in Spark,
thus Giraph is unaware of the presence of a second heap.

\subsection{Experiments with single instance}

In this section we run the single instance experiments and provide an explanation of their performance to use it later to study the interference with co-located experiments.
These experiments map one to one to the co-located experiments of the next section.
DRAM per core is added to the figure titles to show relation between this mapping, and not because it has any impact
for single instance performance. For all figures, each configuration is described with memory capacity for H1 + memory for OS in GB and a label that denotes the division of memory e.g. N2 is 1/2 of total DRAM for Native, N4 is 1/4 of total DRAM for Native. TH H1 denotes 80\% memory for H1 and TH PC denotes 40\% memory for H1 to investigate the PC scenario. LinR and LogR experiments with 10 GB DRAM for H1 and 4 for OS for TH that do not match the 80\% budget baseline are conducted this way, because the OS needs 1 extra GB for cache. This is not an Out of memory (OOM) error for H1 but an adjustment to memory budget.

\begin{figure}[thbp]
\centering
    \includegraphics[width=\linewidth]{./fig/pr32_single.png}
    \caption{ Execution time breakdown for single instances of Spark
        Page Rank for the 4 GB memory-per-core scenario. X axis shows each configuration. Y axis shows execution time in seconds. All missing configurations in the figure are OOM experiments.}
    \label{fig:pr32_single}
        \includegraphics[width=\linewidth]{./fig/linr32_single.png}
    \caption{Execution time breakdown for single instances of Spark
        Linear Regression for the 4 GB memory-per-core scenario. X axis shows each configuration. Y axis shows execution time in seconds. All missing configurations in the figure are OOM experiments.}
    \label{fig:linr32_single}
\end{figure}

\begin{figure}[thbp]
        \centering
    \includegraphics[width=\linewidth]{./fig/logr32_single.png}
    \caption{Execution time breakdown for single instances of Spark
    Logistic Regression for the 4 GB memory-per-core scenario. X axis shows each configuration. Y axis shows execution time in seconds. All missing configurations in the figure are OOM experiments.}
    \label{fig:logr32_single}

    \includegraphics[width=\linewidth]{./fig/cc32_single.png}
    \caption{Execution time breakdown for single instances of Spark
    Connected Component for the 4 GB memory-per-core scenario. X axis shows each configuration.
Y axis shows execution time in seconds. All missing configurations in the figure are OOM experiments.}
    \label{fig:cc32_single}
\end{figure}


\begin{figure}[thbp]
\centering
    \includegraphics[width=\linewidth]{./fig/pr64_single.png}
    \caption{ Execution time breakdown for single instances of Spark
	Page Rank for the 8 GB memory-per-core scenario. X axis shows each configuration. Y axis shows execution time in seconds. All missing configurations in the figure are OOM experiments.}
    \label{fig:pr64_single}
	\includegraphics[width=\linewidth]{./fig/linr64_single.png}
    \caption{Execution time breakdown for single instances of Spark
	Linear Regression for the 8 GB memory-per-core scenario. X axis shows each configuration. Y axis shows execution time in seconds. All missing configurations in the figure are OOM experiments.}
    \label{fig:linr64_single}
\end{figure}

\begin{figure}[thbp]
        \centering
    \includegraphics[width=\linewidth]{./fig/logr64_single.png}
    \caption{Execution time breakdown for single instances of Spark
    Logistic Regression for the 8 GB memory-per-core scenario. X axis shows each configuration. Y axis shows execution time in seconds. All missing configurations in the figure are OOM experiments.}
    \label{fig:logr64_single}

    \includegraphics[width=\linewidth]{./fig/cc64_single.png}
    \caption{Execution time breakdown for single instances of Spark
    Connected Component for the 8 GB memory-per-core scenario. X axis shows each configuration.
Y axis shows execution time in seconds. All missing configurations in the figure are OOM experiments.}
    \label{fig:cc64_single}
\end{figure}
\iffalse
\begin{figure}[thbp]
	\iffalse
	\centering
    \includegraphics[width=\linewidth]{./fig/pr256.png}
    \caption{Execution time breakdown for multiple instances of Spark
    Page Rank in the 16 GB memory-per-core scenario. X axis shows each configuration.
	For example, 48 H1 + 12 OS - N4 is a run with two co-located instances of Native Spark (T4 for TeraHeap) with 48 GB memory for H1 and 12 for the OS to be used as Page Cache. Y axis shows execution time in seconds.}
    \label{fig:}
	\fi
	\centering
    \includegraphics[width=\linewidth]{./fig/linr128_single.png}
    \caption{Execution time breakdown for single instances of Spark
    Linear Regression. X axis shows each configuration.
Y axis shows execution time in seconds. All missing configurations in the figure are OOM experiments.}
    \label{fig:linr128_single}
\end{figure}
\fi

\begin{figure}[thbp]
        \centering
    \includegraphics[width=\linewidth]{./fig/g_pr64_single.png}
    \caption{Execution time breakdown for single instances of Giraph
    Page Rank for the 8 GB memory-per-core scenario. X axis shows each configuration.
        Y axis shows execution time in seconds. All missing configurations in the figure are OOM experiments.}
    \label{fig:g_pr64_single}
    \includegraphics[width=\linewidth]{./fig/g_cdlp64_single.png}
    \caption{Execution time breakdown for single instances of Giraph
    Community Detection Label Propagation for the 8 GB memory-per-core scenario. X axis shows each configuration. 
        Y axis shows execution time in seconds. All missing configurations in the figure are OOM experiments.}
    \label{fig:g_cdlp64_single}
\end{figure}

\begin{figure}[thbp]
        \centering
    \includegraphics[width=\linewidth]{./fig/g_pr128_single.png}
    \caption{Execution time breakdown for single instances of Giraph
    Page Rank for the 16 GB memory-per-core scenario. X axis shows each configuration.
Y axis shows execution time in seconds. All missing configurations in the figure are OOM experiments.}
    \label{fig:g_pr128_single}
    \includegraphics[width=\linewidth]{./fig/g_cdlp128_single.png}
    \caption{Execution time breakdown for single instances of Giraph
    Community Detection Label Propagation for the 16 GB memory-per-core scenario. X axis shows each configuration.
Y axis shows execution time in seconds. All missing configurations in the figure are OOM experiments.}
    \label{fig:g_cdlp128_single}
\end{figure}

Figure \ref{fig:pr32_single} shows single instance performance with Page Rank for Native and TH Spark. These experiments correspond to the co-located runs of figure \ref{fig:pr32}. The first bar shows performance of Native Spark for 12 GB DRAM. The second bar shows execution breakdown of TH Spark for 12 GB DRAM. This figure shows that Native Spark suffers from GC, while TH absorbs this overhead.

Figure \ref{fig:linr32_single} shows single instance performance with Page Rank for Native and TH Spark. These experiments correspond to the co-located runs of figure \ref{fig:linr32}. The first bar shows performance of Native Spark for 12 GB DRAM. The second bar shows execution breakdown of TH Spark for 12 GB DRAM. This figure shows that Native Spark suffers from GC and S/D, while TH absorbs these overheads.

Figure \ref{fig:logr32_single} shows single instance performance with Page Rank for Native and TH Spark. These experiments correspond to the co-located runs of figure \ref{fig:logr32}. The first bar shows performance of Native Spark for 12 GB DRAM. The second bar shows execution breakdown of TH Spark for 12 GB DRAM. This figure shows that Native Spark suffers from GC and S/D, while TH absorbs these overheads.

Figure \ref{fig:cc32_single} shows single instance performance with Page Rank for Native and TH Spark. These experiments correspond to the co-located runs of figure \ref{fig:cc32}. The first bar shows performance of Native Spark for 12 GB DRAM. The second bar shows execution breakdown of TH Spark for 12 GB DRAM. This figure shows that Native Spark suffers from GC, while TH absorbs this overhead.

Figure \ref{fig:pr64_single} shows single instance performance with Page Rank for Native and TH Spark. These experiments correspond to the co-located runs of figure \ref{fig:pr64}. The first two bars show performance of Native Spark for 28 and 14 GB DRAM. When H1 decreases, Native suffers from longer and more frequent GC cycles, thus we see an increment to Major GC. S/D and other time remain the same as Read/Write traffic remains the same. The rest four bars show performance for TH Spark for 28 (80\% and 40\% for H1), 14 (80\% and 40\% for H1) and 7 (80\% for H1) GB DRAM. For TH PC there is no memory for the system. As we said in our methodology, for TeraHeap we investigate setups with DRAM budgets where both H1 and PC dominate. As H1 decreases for TeraHeap, we see an increase to Major GC in the last 2 bars. Other time and S/D remain the same.

Figure \ref{fig:linr64_single} shows single instance performance with Linear Regression for Native and TH Spark. These experiments correspond to the co-located runs of figure \ref{fig:linr64}. The first two bars show performance of Native Spark for 28 and 14 GB DRAM. When H1 decreases, Native suffers from longer and more frequent GC cycles thus we see an increment to Major GC. S/D has a slight increase because of increased read traffic caused by memory pressure. Write traffic remains the same because objects in Spark are immutable. The rest four bars show performance for TH Spark for 28 (80\% and 40\% for H1) and 14 (71\% and 40\% for H1) GB DRAM. As H1 decreases for TeraHeap, we see an increase to Major GC in the last 2 bars. Other time shows slight differences because of cache size. That can be seen from the second and third bar which have the same amount for H1 and a big difference in cache. S/D remains the same.

Figure \ref{fig:logr64_single} shows single instance performance with Logistic Regression for Native and TH Spark. These experiments correspond to the co-located runs of figure \ref{fig:logr64}. The first two bars show performance of Native Spark for 28 and 14 GB DRAM. When H1 decreases Native, suffers from longer and more frequent GC cycles, thus we see a significant increment to Major GC. S/D has a huge increase of almost 30\% because of increased read traffic caused by memory pressure. Write traffic remains the same because objects in Spark are immutable. The rest four bars show performance for TH Spark for 28 (80\% and 40\% for H1) and 14 (71\% and 40\% for H1) GB DRAM. As H1 decreases for TeraHeap, we see some notable differences to GC. Other time shows differences because of cache size. That can be seen from the second and third bar which have the same amount for H1 and a big difference in cache. S/D remains the same.

Figure \ref{fig:cc64_single} shows single instance performance with Connected Component for Native and TH Spark. These experiments correspond to the co-located runs of figure \ref{fig:cc64}. The first two bars show performance of Native Spark for 28 and 14 GB DRAM. When H1 decreases, Native suffers from longer and more frequent GC cycles, thus we see an increment to Major GC. S/D remains the same. Write traffic remains the same because objects in Spark are immutable. The rest four bars show performance for TH Spark for 28 (80\% and 40\% for H1) and 14 (80\% and 40\% for H1) GB DRAM. As H1 decreases for TeraHeap, we see an increase to Minor GC in the last bar. Other time and S/D remain the same.
\iffalse
Figure \ref{fig:linr128_single} shows single instance performance with Linear Regression for Native and TH Spark. These experiments correspond to the co-located runs of figure \ref{fig:linr128}. The first two bars show performance of Native Spark for 60 and 30 GB DRAM. When H1 decreases Native suffers from longer and more frequent GC cycles thus we see an increment to Major GC. S/D has a slight increase because of increased Read traffic caused by memory pressure. Write traffic remains the same because objects in Spark are immutable. The rest four bars show performance for TH Spark for 60 (80\% and 40\% for H1) and 30 (80\% and 40\% for H1) GB DRAM. As H1 decreases for TeraHeap we see an increase to Major GC. Other time shows slight differences because of cache size. S/D remains the same.
\fi
Figures \ref{fig:g_pr64_single} and \ref{fig:g_cdlp64_single} show performance only for TH with 80\% budget for H1, because all other experiments are OOM, thus  we cannot provide a comparison with other experiments.

Figure \ref{fig:g_pr128_single} shows single instance performance with Page Rank for Native and TH Giraph. These experiments correspond to the co-located runs of figure \ref{fig:g_pr128}. The first bar shows performance of Native Giraph for 60 GB DRAM. The rest three bars show performance for TH Giraph for 60 (80\% and 40\% for H1) and 30 (80\% for H1) GB DRAM. As H1 decreases for TeraHeap, we see an increase to Major GC  and Other time. Other time changes by both H1 and Page Cache differences. We see that H1 affects writes in a significant way, because objects are mutable in Giraph and decreasing H1 creates more traffic to TeraHeap. Page Cache mostly affects read traffic. These can be seen from the progression of the bars in other time.

Figure \ref{fig:g_cdlp128_single} shows single instance performance with Page Rank for Native and TH Giraph. These experiments correspond to the co-located runs of figure \ref{fig:g_pr128}. The first bar shows performance of Native Giraph for 60 GB DRAM. The rest three bars show performance for TH Giraph for 60 (80\% and 40\% for H1) and 30 (80\% for H1) GB DRAM. As H1 decreases for TeraHeap, we see an increase to Major GC  and Other time. Other time changes by both H1 and Page Cache differences. We see that H1 affects writes in a significant way, because objects are mutable in Giraph, and decreasing H1 creates more traffic to TeraHeap. Page Cache mostly affects read traffic. These can be seen from the progression of the bars in other time.

In conclusion, in all Spark experiments we see that H1 has significant impact for Native, while for TeraHeap H1 is significant too, but not as significant as for Native. For Native, we saw no differences with variable Page Cache sizes for any of the experiments, thus we do not show them here. For TH, PC shows improvements of 5\% to 7\% for ML workloads, except the LinR experiment that maps to the co-located experiment for 8 GB per core. Number of GCs and Read/Write traffic figures are not included because all preserve the same pattern described above. For Native Spark the number of GCs and read traffic increases significantly as H1 decreases. For TH Spark, number of GCs also increase slightly as H1 decreases and read/write traffic remains the same. Read traffic increases slightly as PC decreases for TH. For Giraph, H1 also affects read/write traffic significantly for both Native and TH and PC decreases read traffic significantly for TH.

\subsection{Experiments with co-located instances}

Here, we look at the co-located experiments of Spark and Giraph in all memory per core categories.
Any runs that are not shown should be considered experiments that run Out of memory (OOM) for H1.
N2 (T for TeraHeap) means that we have a co-located experiment with 2 instances of Native Spark or Giraph.
Average throughout is the result of the division of the result of the multiplication of the number of instances with dataset size (same per instance) and the execution time of the slowest instance in execution. Realizations on other time are included in a different subsection.
All results are rounded to the upper bound integer except costs, because for monetary cost even small amounts are significant.

\begin{figure}[thbp]
\centering
    \includegraphics[width=\linewidth]{./fig/pr32.png}
    \caption{Execution time breakdown for co-located instances of Spark
    Page Rank in the 4 GB memory-per-core scenario. X axis shows each configuration.
        Y axis shows execution time in seconds.}
    \label{fig:pr32}
        \includegraphics[width=\linewidth]{./fig/linr32.png}
    \caption{Execution time breakdown for co-located instances of Spark
    Linear Regression in the 4 GB memory-per-core scenario. X axis shows each configuration.
        Y axis shows execution time in seconds.}
    \label{fig:linr32}
\end{figure}

\begin{figure}[thbp]
        \centering
    \includegraphics[width=\linewidth]{./fig/logr32.png}
    \caption{Execution time breakdown for co-located instances of Spark
    Logistic Regression in the 4 GB memory-per-core scenario. X axis shows each configuration.
        Y axis shows execution time in seconds.}
    \label{fig:logr32}

    \includegraphics[width=\linewidth]{./fig/cc32.png}
    \caption{Execution time breakdown for co-located instances of Spark
    Connected Component in the 4 GB memory-per-core scenario. X axis shows each configuration.
        Y axis shows execution time in seconds.}
    \label{fig:cc32}
\end{figure}

\begin{figure}[thbp]
\centering
    \includegraphics[width=\linewidth]{./fig/pr64.png}
    \caption{Execution time breakdown for co-located instances of Spark
    Page Rank in the 8 GB memory-per-core scenario. X axis shows each configuration.
	Y axis shows execution time in seconds.}
    \label{fig:pr64}
	\includegraphics[width=\linewidth]{./fig/linr64.png}
    \caption{Execution time breakdown for co-located instances of Spark
    Linear Regression in the 8 GB memory-per-core scenario. X axis shows each configuration.
	Y axis shows execution time in seconds.}
    \label{fig:linr64}
\end{figure}

\begin{figure}[thbp]
        \centering
    \includegraphics[width=\linewidth]{./fig/logr64.png}
    \caption{Execution time breakdown for co-located instances of Spark
    Logistic Regression in the 8 GB memory-per-core scenario. X axis shows each configuration.
	Y axis shows execution time in seconds.}
    \label{fig:logr64}

    \includegraphics[width=\linewidth]{./fig/cc64.png}
    \caption{Execution time breakdown for co-located instances of Spark
    Connected Component in the 8 GB memory-per-core scenario. X axis shows each configuration.
	Y axis shows execution time in seconds.}
    \label{fig:cc64}
\end{figure}
\iffalse
\begin{figure}[thbp]
	\iffalse
        \centering
    \includegraphics[width=\linewidth]{./fig/pr256.png}
    \caption{Execution time breakdown for co-located instances of Spark
    Page Rank in the 16 GB memory-per-core scenario. X axis shows each configuration.
	Y axis shows execution time in seconds.}
    \label{fig:pr256}
	\fi
	\centering
    \includegraphics[width=\linewidth]{./fig/linr128.png}
    \caption{Execution time breakdown for co-located instances of Spark
    Linear Regression in the 8 GB memory-per-core scenario. X axis shows each configuration.
Y axis shows execution time in seconds.}
    \label{fig:linr128}
\end{figure}
\fi
\begin{figure}[thbp]
        \centering
    \includegraphics[width=\linewidth]{./fig/g_pr64.png}
    \caption{Execution time breakdown for co-located instances of Giraph
    Page Rank in the 8 GB memory-per-core scenario. X axis shows each configuration.
	Y axis shows execution time in seconds.}
    \label{fig:g_pr64}
    \includegraphics[width=\linewidth]{./fig/g_cdlp64.png}
    \caption{Execution time breakdown for co-located instances of Giraph
    Community Detection Label Propagation in the 8 GB memory-per-core scenario. X axis shows each configuration. 
	Y axis shows execution time in seconds.}
    \label{fig:g_cdlp64}
\end{figure}

\begin{figure}[thbp]
        \centering
    \includegraphics[width=\linewidth]{./fig/g_pr128.png}
    \caption{Execution time breakdown for co-located instances of Giraph
    Page Rank in the 16 GB memory-per-core scenario. X axis shows each configuration.
	Y axis shows execution time in seconds.}
    \label{fig:g_pr128}
    \includegraphics[width=\linewidth]{./fig/g_cdlp128.png}
    \caption{Execution time breakdown for co-located instances of Giraph
    Community Detection Label Propagation in the 16 GB memory-per-core scenario. X axis shows each configuration. Y axis shows execution
	time in seconds.}
    \label{fig:g_cdlp128}
\end{figure}

\begin{figure}[thbp]
        \centering
        \includegraphics[width=\linewidth]{./fig/PR_64_THR.png}
    \caption{Native and TeraHeap Spark average throughput
        as the number of instances increases under 8 GB DRAM per core running Page Rank.}
\label{fig:pr_64_thr}
        \includegraphics[width=\linewidth]{./fig/LINR_64_THR.png}
    \caption{Native and TeraHeap Spark average throughput
        as the number of instances increases under 8 GB DRAM per core running Linear Regression.}
                \label{fig:linr_64_thr}
\end{figure}

\begin{figure}[thbp]
        \centering
        \includegraphics[width=\linewidth]{./fig/LOGR_64_THR.png}
    \caption{Native and TeraHeap Spark average throughput
        as the number of instances increases under 8 GB DRAM per core running Logistic Regression.}
                \label{fig:logr_64_thr}
        \includegraphics[width=\linewidth]{./fig/CC_64_THR.png}
    \caption{Native and TeraHeap Spark average throughput
        as the number of instances increases under 8 GB DRAM per core running Connected Component.}
                \label{fig:cc_64_thr}
\end{figure}

\begin{figure}[thbp]
        \centering
        \includegraphics[width=\linewidth]{./fig/G_PR_128_THR.png}
    \caption{Native and TeraHeap Giraph average throughput
        as the number of instances increases under 16 GB DRAM per core running Page Rank.}
        \label{fig:g_pr128_thr}
        \includegraphics[width=\linewidth]{./fig/G_CDLP_128_THR.png}
    \caption{Native and TeraHeap Giraph average throughput
        as the number of instances increases under 16 GB DRAM per core running Page Rank.}
        \label{fig:g_cdlp128_thr}
\end{figure}

We explain each figure from 4 aspects:
\begin{itemize}
\item{The differences in the time breakdown while number of instances increase for each configuration.}
\item{A comparison between the different configurations while instances increase.}
\item{Interference between the single instance and co-located instances}
\item{A comparison between H1 and Page Cache dominating configurations}
\item{Realizations on performance difference between different memory per core scenarios}
\end{itemize}


\subsubsection{4 GB DRAM per core}

Figure \ref{fig:pr32} shows execution time of co-located
Native-TeraHeap Spark instances running PageRank with 8 GB
dataset per instance in the 4 GB DRAM per core scenario.
In the graph, we witness the performance of 2 runs. The first run is with 2 co-located Native Spark instances.
The other run is with 2 co-located TH Spark instances with H1 dominating Page Cache.
We could run the experiment where PC dominates H1, but we did not, because of lack of time. 
Each instance of the Native run uses 10 GB DRAM for H1 (Java Heap) and 2 GB for rest of the services.
The TH run uses 9 GB DRAM for H1 and 3 GB for Page Cache for each instance.

Considering the first aspect, we do not have the needed runs to analyze it.

From the second aspect, we see that as Native Spark starves from more GC and S/D, TeraHeap nearly eliminates these overheads. TeraHeap has 32\% speedup and 33\% more average throughput for 2 instances when compared to the corresponding Native runs.

Figure \ref{fig:linr32} shows execution time of co-located
Native-TeraHeap Spark instances running LinearRegression with 8 GB
dataset per instance in the 4 GB DRAM per core scenario.
In the graph, we witness the performance of 2 runs. The first run is with 2 co-located Native Spark instances.
The other run is with 2 co-located TH Spark instances with H1 dominating Page Cache.
We could run the experiment where PC dominates H1, but we did not, because of lack of time.
Each instance of the Native run uses 10 GB DRAM for H1 (Java Heap) and 2 GB for rest of the services.
The TH run uses 8 GB DRAM for H1 and 4 GB for Page Cache for each instance.

Considering the first aspect, we do not have the needed runs to analyze it.

From the second aspect, we see that as Native Spark starves from more GC and S/D, TeraHeap nearly eliminates these overheads. TeraHeap has 58\% speedup and 59\% more average throughput for 2 instances when compared to the corresponding Native runs.

Figure \ref{fig:logr32} shows execution time of co-located
Native-TeraHeap Spark instances running PageRank with 8 GB
dataset per instance in the 4 GB DRAM per core scenario.
In the graph, we witness the performance of 2 runs. The first run is with 2 co-located Native Spark instances.
The other run is with 2 co-located TH Spark instances with H1 dominating Page Cache.
We could run the experiment where PC dominates H1, but we did not, because of lack of time.
Each instance of the Native run uses 10 GB DRAM for H1 (Java Heap) and 2 GB for rest of the services.
The TH run uses 8 GB DRAM for H1 and 4 GB for Page Cache for each instance.

Considering the first aspect, we do not have the needed runs to analyze it.

From the second aspect, we see that as Native Spark starves from more GC and S/D, TeraHeap nearly eliminates these overheads. TeraHeap has 58\% speedup and 59\% more average throughput for 2 instances when compared to the corresponding Native runs.

Figure \ref{fig:cc32} shows execution time of co-located
Native-TeraHeap Spark instances running PageRank with 8 GB
dataset per instance in the 4 GB DRAM per core scenario.
In the graph, we witness the performance of 2 runs. The first run is with 2 co-located Native Spark instances.
The other run is with 2 co-located TH Spark instances with H1 dominating Page Cache.
We could run the experiment where PC dominates H1, but we did not, because of lack of time.
Each instance of the Native run uses 10 GB DRAM for H1 (Java Heap) and 2 GB for rest of the services.
The TH run uses 9 GB DRAM for H1 and 3 GB for Page Cache for each instance.

Considering the first aspect, we do not have the needed runs to analyze it.

From the second aspect, we see that as Native Spark starves from more GC and S/D, TeraHeap nearly eliminates these overheads. TeraHeap has 32\% speedup and 33\% more average throughput for 2 instances when compared to the corresponding Native runs.

\subsubsection{8 GB DRAM per core}

Figure \ref{fig:pr64} and \ref{fig:pr_64_thr} show execution time and average throughput of co-located
Native-TeraHeap Spark instances running PageRank with 8 GB
dataset per instance in the 8 GB DRAM per core scenario.
Starting from the left of the graph, the first 6 bars show the
performance of 3 runs. The first run is with 2 co-located Native Spark instances.
Another run with 2 co-located TH Spark instances with H1 dominating Page Cache,
and a third run with 2 co-located TH Spark instances where Page Cache dominates H1.
Each instance of the first 2 runs uses 22 GB DRAM for H1 (Java Heap) and 6 GB for rest of the services.
The third run uses 11 GB DRAM for H1 and 17 GB for Page Cache for each instance. 
The next 12 bars show the performance of another 3 runs. The first run is with 4 co-located Native Spark instances.
Another run with 4 co-located TH Spark instances with H1 dominating Page Cache,
and a third run with 4 co-located TH Spark instances where Page Cache dominates H1.
Each instance of the first run uses 11 GB DRAM for H1 (Java Heap) and 3 GB for rest of the services.
The second run uses 11 GB DRAM for H1 and 3 GB for Page Cache for each instance.
The third run uses 6 GB DRAM for H1 and 8 GB for Page Cache for each instance.
The last 8 bars refer to 8 co-located instances of TeraHeap Spark only. 
We were unable to decrease H1 enough to run 8 co-located instances of Native Spark,
because JVM runs out of memory. Each instance of the run uses 4 GB DRAM for H1 (Java Heap) and 3 GB for Page Cache.

Considering the first aspect, we see that Minor and Major GC increase dramatically for Native Spark along with significant increase to Other time. Minor and Major GC differences are witnessed, because the heap capacity decreases and that causes memory pressure. TeraHeap Spark shows a slight increase to Major GC, while the number of instances increases. This is because of the decreasing heap capacity. We suspect device throughput reaching its limit with increasing number of instances, as the cause to other time for both Native and TH. S/D is completely absorbed by MMIO. For Native Spark 2 co-located instances have 55\% speedup in execution time compared to 4 co-located instances, and provide 20\% more average throughput. For TH H1 2 co-located instances have 40\% speedup in execution time compared to 4 co-located instances and provide 14\% more average throughput. For TH 8 co-located instances have 50 and 83\% speedup against 4 and 2 instances accordingly.

From the second aspect, as instances increase in the server the benefit gap between Native and TeraHeap Spark becomes bigger. As Native Spark starves from more GC and S/D, TeraHeap maintains its benefits. TeraHeap has 50 and 25\% speedup for 2 and 4 instances when compared to the corresponding Native runs. If we compare TeraHeap 8 instances to the 4 instances of Native TeraHeap has 33\% worse performance but 33\% more average throughput.

Figure \ref{fig:linr64} and \ref{fig:linr_64_thr} show the execution time and average throughput of co-located
Native-TeraHeap Spark instances running LinearRegression with 64 GB
dataset per instance in the 8 GB DRAM per core scenario.
Starting from the left of the graph, the first 6 bars show the
performance of 3 runs. The first run is with 2 co-located Native Spark instances.
Another run with 2 co-located TH Spark instances with H1 dominating Page Cache,
and a third run with 2 co-located TH Spark instances where Page Cache dominates H1.
Each instance of the first 2 runs uses 22 GB DRAM for H1 (Java Heap) and 6 GB for rest of the services.
The third run uses 11 GB DRAM for H1 and 17 GB for Page Cache for each instance.
The rest 12 bars show the performance of another 3 runs. The first run is with 4 co-located Native Spark instances.
Another run with 4 co-located TH Spark instances with H1 dominating Page Cache
and a third run with 4 co-located TH Spark instances where Page Cache dominates H1.
Each instance of the first run uses 11 GB DRAM for H1 (Java Heap) and 3 GB for rest of the services.
The second run uses 10 GB DRAM for H1 and 4 GB for Page Cache for each instance.
The third run uses 6 GB DRAM for H1 and 8 GB for Page Cache for each instance.

Considering the first aspect, we see that GC and S/D increase dramatically for Native Spark along with significant increase to Other time. GC differences are witnessed because the heap capacity decreases, and that causes memory pressure. TeraHeap Spark shows a slight increase to Major GC while the number of instances increases. This is because of the decreased heap capacity. We suspect device throughput reaching its limit with increasing number of instances as the cause to other time for both Native and TH. S/D is completely absorbed by MMIO. For Native Spark 2 co-located instances have 71\% speedup in execution time compared to 4 co-located instances and provide 46\% more average throughput. For TH H1 2 co-located instances have 50\% speedup in execution time compared to 4 co-located instances, and provide 8\% more average throughput. For TH PC performance is the same with TH H1.

From the second aspect, as instances increase in the server the benefit gap between Native and TeraHeap Spark becomes bigger. As Native Spark starves from more GC and S/D, TeraHeap maintains its benefits. That is shown by the speedups where TeraHeap has 25\% and 57\% speedup and 48\% and 66\% more average throughput for 2 and 4 instances when compared to the corresponding Native runs.

Figures \ref{fig:logr64} and \ref{fig:logr_64_thr} show execution time and average throughput of co-located
Native-TeraHeap Spark instances running Logistic Regression with 64 GB
dataset per instance in the 8 GB DRAM per core scenario.
Starting from the left of the graph, the first 6 bars show the
performance of 3 runs. The first run is with 2 co-located Native Spark instances.
Another run with 2 co-located TH Spark instances with H1 dominating Page Cache
and a third run with 2 co-located TH Spark instances where Page Cache dominates H1.
Each instance of the first 2 runs uses 22 GB DRAM for H1 (Java Heap) and 6 GB for rest of the services.
The third run uses 11 GB DRAM for H1 and 17 GB for Page Cache for each instance. 
The next 12 bars show the performance of another 3 runs. The first run is with 4 co-located Native Spark instances.
Another run with 4 co-located TH Spark instances with H1 dominating Page Cache
and a third run with 4 co-located TH Spark instances where Page Cache dominates H1.
Each instance of the first run uses 11 GB DRAM for H1 (Java Heap) and 3 GB for rest of the services.
The second run uses 10 GB DRAM for H1 and 3 GB for Page Cache for each instance.
The third run uses 6 GB DRAM for H1 and 7 GB for Page Cache for each instance.

Considering the first aspect, we see that GC and S/D increase dramatically for Native Spark along with significant increase to Other time. GC differences are witnessed because the heap capacity decreases, and that causes memory pressure. TeraHeap Spark shows a slight increase to Major GC while the number of instances increases. This is because of the decreased heap capacity. We suspect device throughput reaching its limit with increasing number of instances, as the cause to other time for both Native and TH. S/D is completely absorbed by MMIO. For Native Spark 2 co-located instances have 62\% speedup in execution time compared to 4 co-located instances and provide 27\% more average throughput. For TH H1 2 co-located instances have 50\% speedup in execution time compared to 4 co-located instances and provides the same throughput. For TH PC performance is the same with TH H1. 

From the second aspect, as instances increase in the server, the benefit gap between Native and TeraHeap Spark becomes bigger. As Native Spark starves from more GC and S/D, TeraHeap maintains its benefits. TeraHeap has 57 and 40\% speedup and 48\% and 66\% increased average throughput for 2 and 4 instances when compared to the corresponding Native runs.

Figure \ref{fig:cc64} and \ref{fig:cc_64_thr} show execution time and average throughput of co-located
Native-TeraHeap Spark instances running Connected Component with 8 GB
dataset per instance in the 8 GB DRAM per core scenario.
Starting from the left of the graph, the first 6 bars show the
performance of 3 runs. The first run is with 2 co-located Native Spark instances.
Another run with 2 co-located TH Spark instances with H1 dominating Page Cache
and a third run with 2 co-located TH Spark instances where Page Cache dominates H1.
Each instance of the first 2 runs uses 22 GB DRAM for H1 (Java Heap) and 6 GB for rest of the services.
The third run uses 11 GB DRAM for H1 and 17 GB for Page Cache for each instance. 
The next 12 bars show the performance of another 3 runs. The first run is with 4 co-located Native Spark instances.
Another run with 4 co-located TH Spark instances with H1 dominating Page Cache
and a third run with 4 co-located TH Spark instances where Page Cache dominates H1.
Each instance of the first run uses 11 GB DRAM for H1 (Java Heap) and 3 GB for rest of the services.
The second run uses 11 GB DRAM for H1 and 3 GB for Page Cache for each instance.
The third run uses 6 GB DRAM for H1 and 8 GB for Page Cache for each instance.

Considering the first aspect, we see that Minor and Major GC increase dramatically for Native Spark along with significant increase to Other time. Minor and Major GC differences are witnessed because the heap capacity decreases, and that causes memory pressure. TeraHeap Spark shows a slight increase to Major GC while the number of instances increases. This is because of the decreasing heap capacity. We suspect device throughput reaching its limit with increasing number of instances, as the cause to other time for both Native and TH. S/D is completely absorbed by MMIO. For Native Spark 2 co-located instances have 57\% speedup in execution time compared to 4 co-located instances and provide 27\% more average throughput. For TH H1 2 co-located instances have 54\% speedup in execution time compared to 4 co-located instances and provides 8\% less throughput.

From the second aspect, as instances increase in the server, the benefit gap between Native and TeraHeap Spark becomes bigger. As Native Spark starves from more GC and S/D, TeraHeap maintains its benefits. TeraHeap has 21 and 15\% speedup and 10\% more throughput for 2 and 4 instances when compared to the corresponding Native runs.

\subsubsection{16 GB DRAM per core}
\iffalse
Figure \ref{fig:linr128} shows the performance of co-located
Native-TeraHeap Spark instances running LinearRegression with 128 GB
dataset per instance in the 16 GB DRAM per core scenario.
Starting from the left of the graph, the first 6 bars show the
performance of 3 runs. The first run is with 2 co-located Native Spark instances.
Another run with 2 co-located TH Spark instances with H1 dominating Page Cache,
and a third run with 2 co-located TH Spark instances where Page Cache dominates H1.
Each instance of the first 2 runs uses 48 GB DRAM for H1 (Java Heap) and 12 GB for rest of the services.
The third run uses 24 GB DRAM for H1 and 36 GB for Page Cache for each instance.
The rest 8 bars show the performance of another 2 runs. The first run is with 4 co-located Native Spark instances.
Another run with 4 co-located TH Spark instances with H1 dominating Page Cache,
and a third run with 4 co-located TH Spark instances where Page Cache dominates H1.
Each instance of the first run uses 24 GB DRAM for H1 (Java Heap) and 6 GB for rest of the services.
The second run uses 24 GB DRAM for H1 and 6 GB for Page Cache for each instance.

Considering the first aspect, we see that GC and S/D increase dramatically for Native Spark along with significant increase to Other time. GC differences are witnessed, because the heap capacity decreases and that causes memory pressure. TeraHeap Spark shows a slight increase to Major GC while the number of instances increases. This is because of the decreased heap capacity. We suspect device throughput reaching its limit with increasing number of instances, as the cause to other time for both Native and TH. S/D is completely absorbed by MMIO. For Native Spark, 2 co-located instances have 57\% speedup in execution time compared to 4 co-located instances and provide 18\% more average throughput. For TH H1, 2 co-located instances have 50\% speedup in execution time compared to 4 co-located instances and provide the same average throughput. For TH PC, 2 co-located instances have 50\% speedup in execution time compared to 4 co-located instances and provide the same average throughput. 

From the second aspect, as instances increase in the server, the benefit gap between Native and TeraHeap Spark becomes bigger. As Native Spark starves from more GC and S/D, TeraHeap maintains its benefits. That is shown by the speedups where TeraHeap has 50\% speedup and 73\% and 77\% more average throughput for 2 and 4 instances when compared to the corresponding Native runs.
\fi
Figures \ref{fig:g_pr64} and \ref{fig:g_cdlp64} show execution time only for TH Giraph with 80\% budget for H1, because all other experiments are
OOM thus we cannot provide a comparison with other experiments.

Figure \ref{fig:g_pr128} and \ref{fig:g_pr128_thr} show execution time and average throughput of co-located
Native-TeraHeap Giraph instances running Page Rank with 13 GB
dataset per instance in the 16 GB DRAM per core scenario.
Starting from the left of the graph, the first 6 bars show the
performance of 3 runs. The first run is with 2 co-located Native Giraph instances.
Another run with 2 co-located TH Giraph instances with H1 dominating Page Cache,
and a third run with 2 co-located TH Instances instances where Page Cache dominates H1.
Each instance of the first 2 runs uses 48 GB DRAM for H1 (Java Heap) and 12 GB for rest of the services.
The third run uses 24 GB DRAM for H1 and 36 GB for Page Cache for each instance.
The rest 4 bars show the performance of another run. The run is with 4 co-located TeraHeap Giraph instances.
Each instance uses 24 GB DRAM for H1 (Java Heap) and 6 GB for rest of the services.


Considering the first aspect Native Giraph does not scale to 4 instances and runs out of memory. TeraHeap Giraph shows significant increase to Major GC while the number of instances increases. This is because of the decreased heap capacity. We suspect device throughput reaching its limit with increasing number of instances, as the cause to other time. For TH H1, 2 co-located instances have 57\% speedup in execution time, compared to 4 co-located instances, and provide the same average throughput. For TH PC, 2 co-located instances have 51\% speedup in execution time compated to 4 co-located instances, and provide the same average throughput.

From the second aspect, TeraHeap is able to scale to 4 instances, while Native runs out of memory. TeraHeap has 11\% speedup and 13\% more average throughput for 2 instances, when compared to the corresponding Native runs.

Figure \ref{fig:g_cdlp128} and \ref{fig:g_cdlp128_thr} show execution time and average throughput of multiple
Native-TeraHeap Giraph instances running CDLP with 13 GB
dataset per instance in the 16 GB DRAM per core scenario.
Starting from the left of the graph, the first 6 bars show the
performance of 3 runs. The first run is with 2 co-located Native Giraph instances.
Another run with 2 co-located TH Giraph instances with H1 dominating Page Cache,
and a third run with 2 co-located TH Instances instances where Page Cache dominates H1.
Each instance of the first 2 runs uses 48 GB DRAM for H1 (Java Heap) and 12 GB for rest of the services.
The third run uses 24 GB DRAM for H1 and 36 GB for Page Cache for each instance.
The rest 4 bars show the performance of another run. The run is with 4 co-located TeraHeap Giraph instances.
Each instance uses 24 GB DRAM for H1 (Java Heap) and 6 GB for rest of the services.

Considering the first aspect, Native Giraph does not scale to 4 instances and runs out of memory. TeraHeap Giraph shows significant increase to Major GC, while the number of instances increases. This is because of the decreased heap capacity. We suspect device throughput reaching its limit with increasing number of instances, as the cause to other time. For TH H1, 2 co-located instances have 63\% speedup in execution time, compared to 4 co-located instances and provide 27\% more average throughput. For TH PC, 2 co-located instances have 61\% speedup in execution time, compared to 4 co-located instances and 27\% more average throughput. From the second aspect, TeraHeap is able to scale to 4 instances while Native runs out of memory. TeraHeap has 9\% speedup and 7\% more average throughput for 2 instances, when compared to the corresponding Native runs.

\subsubsection{Realizations for other time}
For both Spark and Giraph, we suspect device throughput reaching its limit with increasing number of instances, as the cause to other time for both Native and TH. TH has increased other time compared to Native, because of the IO granularity of entire pages despite Native having increased read traffic to TH. Native knows exactly what objects to read doing small reads while TeraHeap brings unuseful objects to memory. For Giraph, TeraHeap has increased read/write traffic, compared to Native and both the difference in IO methods, and read/write traffic leads to increased other time.

\subsubsection{Realizations on performance difference between different memory per core scenarios}
For Spark we see that 4 GB memory per core is a bound to run more than 2 instances. For Giraph, we see than Native is unable to run any experiments under 4 and 8 GB memory per core, while TH is able to run with 2 instances proving that lacking enough memory per instance is a bound for execution, while avoiding GC and S/D enables execution.

\iffalse
\subsubsection{16 GB DRAM per core}

Figure \ref{fig:pr256} shows the performance of multiple
Native-TeraHeap Spark instances running PageRank with 32 GB
dataset per instance in our 256 GB DRAM machine.
The graph, shows the
performance of 3 runs. The first run is with 4 co-located Native Spark instances.
Another run with 4 colocated TH Spark instances with H1 dominating Page Cache.
Each instance of the first 8 runs uses 48 GB DRAM for H1 (Java Heap), and 12 GB for rest of the services including Page Cache.
Each instance of the first run uses 27 GB DRAM for H1 (Java Heap) and 7 GB for rest of the services.
The second run uses 27 GB DRAM for H1 and 7 GB for Page Cache for each TH instance.
The third run uses 14 GB DRAM for H1 and 20 GB for Page Cache for each TH instance.
Considering the first aspect, we see that GC and S/D increase dramatically for TeraHeap Spark along with significant increase to Other time. GC differences are witnessed because the heap capacity decreases, and that causes memory pressure. TeraHeap Spark shows a slight increase to Minor GC, while the number of instances increases. This is because of the decreased heap capacity. For Native Spark, 2 co-located instances have 57\% speedup in execution time, compared to 4 co-located instances, and provide 18\% more average throughput. For TH H1, 2 co-located instances have 50\% speedup in execution time, compared to 4 co-located instances, and provide the same average throughput. For TH PC, 2 co-located instances have 50\% speedup in execution time, compated to 4 co-located instances, and provide the same average throughput. So choosing H1 or PC setup for TH does not make any up or downsides. Native PC setup is not shown in the figure because PC does not have any impact and decreasing H1 would obviously downgrade performance compared to Native H1.
S/D is completely absorbed by MMIO. From the third aspect, as instances increase in the server the benefit gap between Native and TeraHeap Spark becomes bigger. As Native Spark starves from more GC and S/D, TeraHeap maintains its benefits. That is shown by the speedups where TeraHeap has 50\% speedup and 73\% and 77\% more average throughput for 2 and 4 instances when compared to the corresponding Native runs.
\fi

\subsubsection{Interference with single instance}

\begin{table}[thbp]
  \centering
  \caption{Interference for each configuration with co-located instances with corresponding single instance experiment.
	FW = framework, Conf. = configuration, M/C = Memory per core, #I = Number of instances, Interf. = interference }
  \label{tab:interference}
  \begin{tabular}{|c|c|c|c|c|}
    \hline
	  \textbf{FW} & \textbf{Conf.} & \textbf{M/C (GB)} & \textbf{\#I} & \textbf{Interf. \%} \\
    \hline
          Spark & PR Native & 4 & 2 & 19 \\
          Spark & PR TH & 4 & 2 & 47 \\
	  Spark & PR TH H1 & 8 & 2 & 63 \\
	  Spark & PR TH PC & 8 & 2 & 59 \\
	  Spark & PR TH H1 & 8 & 4 &  82 \\
	  Spark & PR TH PC & 8 & 4 & 84 \\
	  Spark & PR TH & 8 & 8 & 92 \\
          Spark & LINR Native & 4 & 2 & 45 \\
          Spark & LINR TH & 4 & 2 & 48 \\
	  Spark & LINR Native & 8 & 2 & 32  \\
	  Spark & LINR Native & 8 & 4 & 80 \\
	  Spark & LINR TH H1 & 8 & 2 & 52 \\
	  Spark & LINR TH PC & 8 & 2 & 53 \\
	  Spark & LINR TH H1 & 8 & 4 & 78 \\
	  Spark & LINR TH PC & 8 & 4 & 80 \\
	  Spark & LINR Native & 8 & 2 & 49 \\
          Spark & LOGR Native & 4 & 2 & 46 \\
          Spark & LOGR TH & 4 & 2 & 48 \\
	  Spark & LOGR Native & 8 & 2 & 45 \\
	  Spark & LOGR Native & 8 & 4 & 71 \\
	  Spark & LOGR TH H1 & 8 & 2 & 44 \\
	  Spark & LOGR TH PC & 8 & 2 & 44 \\
	  Spark & LOGR TH H1 & 8 & 4 & 73 \\
	  Spark & LOGR TH PC & 8 & 4 & 75 \\
          Spark & CC Native & 4 & 2 & 40 \\
          Spark & CC TH & 4 & 2 & 51 \\
          Spark & CC Native & 8 & 2 & 56 \\
          Spark & CC Native & 8 & 4 & 75 \\
          Spark & CC TH H1 & 8 & 2 & 66 \\
          Spark & CC TH PC & 8 & 2 & 66 \\
          Spark & CC TH H1 & 8 & 4 & 84  \\
          Spark & CC TH PC & 8 & 4 & 76 \\
	  Giraph & PR TH & 8 & 2 & 37 \\
	  Giraph & CDLP TH & 8 & 2 & 27 \\
          Giraph & PR Native & 16 & 2 & 19 \\
          Giraph & PR TH H1 & 16 & 2 & 21 \\
          Giraph & PR TH PC & 16 & 2 & 38 \\
          Giraph & PR TH & 16 & 4 & 55 \\
          Giraph & CDLP Native & 16 & 2 & 41 \\
          Giraph & CDLP TH H1 & 16 & 2 & 45 \\
          Giraph & CDLP TH PC & 16 & 2 & 30 \\
          Giraph & CDLP TH & 16 & 4 & 67 \\
    \hline
  \end{tabular}
\end{table}


Table \ref{tab:interference} shows the percentage of interference i.e. speedup of single instance against the corresponding co-located experiment. For Native Spark for 2 to 4 co-located instances experiments there is 19 to 80\% interference. For TeraHeap Spark for 2 to 4 co-located instances experiments there is 32 to 84\% interference. Both offloading techniques have similar interference ranges which are more than 50\% in half of the experiments. For Native Giraph there is 19\% interference for PR and 41\% for CDLP with 2 co-located instances. The first is really reduced compared to the Native Spark 2 co-located instances experiments. For TH Giraph there is 21 to 67 \% interference. For 4 co-located instances experiments TH Giraph has significantly less interference than Spark. In conclusion we wee that interference increases as number of instances increases for both Spark and Giraph. Experiments with 2 co-located instances and an interference under 50\% have better average throughput than single instance and the same happens for experiments with 4 co-located instances with interference under 25\%. The latter never happens.

\subsubsection{Does H1 or PageCache offer better performance?}
We don't investigate Page Cache-dominated cgroup budgets for Native Spark or Giraph, since we have seen that it does not make a difference. For TeraHeap Spark, Page Cache provides slightly better average throughput for 2 co-located instances in ML. In speedup, this is 5\% for LinR and 6\% for LogR, while for 4 instances H1 dominates PC. For the Spark GraphX experiments, we witness the same average throughput for both 2 and 4 co-located instances experiments. For TH Giraph, H1 dominates PC in terms of average throughput. That is, because H1 affects Write traffic in Giraph and Page Cache absorbs mostly reads. In conclusion, based on average throughput, it seems someone would still choose H1 dominated setups for TeraHeap as well.

\subsubsection{Accuracy of experiments}

\begin{table}[thbp]
  \centering
  \caption{Standard deviation for each configuration and number of co-located instances.
        FW=framework, Conf. = configuration, M/C = memory per core, #I=number of instances, St. dev.=standard deviation}
  \label{tab:std-dev}
  \begin{tabular}{|c|c|c|c|c|}
    \hline
          \textbf{FW} & \textbf{Conf.} & \textbf{M/C (GB)} & \textbf{\#I} & \textbf{St. dev. \%} \\
    \hline
          Spark & PR Native & 8 & 2 & 2\\
          Spark & PR Native & 8 & 4 & 6\\
          Spark & PR TH H1 & 8 & 2 & 1 \\
          Spark & PR TH H1 & 8 & 4 & 1 \\
          Spark & LINR Native & 8 & 2 & 2 \\
          Spark & LINR Native & 8 & 4 & 3 \\
          Spark & LINR TH H1 & 8 & 2 & 1 \\
          Spark & LINR TH H1 & 8 & 4 & 2 \\
          Spark & LOGR Native & 8 & 2 & 10 \\
          Spark & LOGR Native & 8 & 4 & 0 \\
          Spark & LOGR TH H1 & 8 & 2 & 3 \\
          Spark & LOGR TH H1 & 8 & 4 & 5 \\
          Spark & CC Native & 8 & 2 & 2 \\
          Spark & CC Native & 8 & 4 & 7 \\
          Spark & CC TH H1 & 8 & 2 & 3 \\
          Spark & CC TH H1 & 8 & 4 & 0 \\
          Giraph & PR TH H1 & 8 & 2 & 6 \\
          Giraph & CDLP Native & 16 & 2 & 4 \\
          Giraph & CDLP TH H1 & 16 & 2 & 5 \\
    \hline
  \end{tabular}
\end{table}

We repeated all experiments for 8 and 16 memory per core with 2 and 4 instances for Spark except with TH PC and 2 instances for Giraph a second time to estimate standard deviation. We left these experiments out because of lack of time. Table \ref{tab:std-dev} shows that 
all experiments have less than 7\% standard deviation except one experiment with Spark for 10\%. Also co-located experiments have under 7\% difference in-between the end of execution of each co-located instance except Native Spark CC with 4 co-located instances under 4 GB DRAM per core with 14\%. This is important, because when one instance has finished the interference decreases for the rest.

\subsection{Is the CPU utilization of the application increasing by reducing GC and S/D?}

\begin{figure}[thbp]
        \centering
        \includegraphics[width=\linewidth]{./fig/PR_64_UTIL.png}
    \caption{Native and TeraHeap Spark total CPU utilization
        as the number of instances increases under 8 GB DRAM per core running Page Rank.}
\label{fig:pr_64_util}
        \includegraphics[width=\linewidth]{./fig/LINR_64_UTIL.png}
    \caption{Native and TeraHeap Spark total CPU utilization
        as the number of instances increases under 8 GB DRAM per core running Linear Regression.}
                \label{fig:linr_64_util}
\end{figure}

\begin{figure}[thbp]
        \centering
        \includegraphics[width=\linewidth]{./fig/LOGR_64_UTIL.png}
    \caption{Native and TeraHeap Spark total CPU utilization
        as the number of instances increases under 8 GB DRAM per core running Logistic Regression.}
                \label{fig:logr_64_util}

        \includegraphics[width=\linewidth]{./fig/CC_64_UTIL.png}
    \caption{Native and TeraHeap Spark total CPU utilization
        as the number of instances increases under 8 GB DRAM per core running Connected Component.}
                \label{fig:cc_64_util}
\end{figure}

\begin{figure}[thbp]
        \centering
        \includegraphics[width=\linewidth]{./fig/G_PR_128_UTIL.png}
    \caption{Native and TeraHeap Giraph total CPU utilization
        as the number of instances increases under 8 GB DRAM per core running Page Rank.}
                \label{fig:g_pr_128_util}

        \includegraphics[width=\linewidth]{./fig/G_CDLP_128_UTIL.png}
    \caption{Native and TeraHeap Giraph total CPU utilization
        as the number of instances increases under 8 GB DRAM per core running Community Detection Label Propagation.}
                \label{fig:g_cdlp_128_util}
\end{figure}

\begin{figure}[thbp]
        \centering
        \includegraphics[width=\linewidth]{./fig/pr32_cycles.png}
    \caption{Native and TeraHeap Spark CPU cycles under 4 GB DRAM per core running Page Rank.}
\label{fig:pr32_cycles}
        \includegraphics[width=\linewidth]{./fig/linr32_cycles.png}
    \caption{Native and TeraHeap Spark CPU cycles under 4 GB DRAM per core running Linear Regression.}
                \label{fig:linr32_cycles}
\end{figure}

\begin{figure}[thbp]
        \centering
        \includegraphics[width=\linewidth]{./fig/logr32_cycles.png}
    \caption{Native and TeraHeap Spark CPU cycles under 4 GB DRAM per core running Logistic Regression.}
                \label{fig:logr32_cycles}

        \includegraphics[width=\linewidth]{./fig/cc32_cycles.png}
    \caption{Native and TeraHeap Spark CPU cycles under 4 GB DRAM per core running Connected Component.}
                \label{fig:cc32_cycles}
\end{figure}


\begin{figure}[thbp]
        \centering
        \includegraphics[width=\linewidth]{./fig/pr64_cycles.png}
    \caption{Native and TeraHeap Spark CPU cycles under 8 GB DRAM per core running Page Rank.}
\label{fig:pr64_cycles}
        \includegraphics[width=\linewidth]{./fig/linr64_cycles.png}
    \caption{Native and TeraHeap Spark CPU cycles under 8 GB DRAM per core running Linear Regression.}
                \label{fig:linr64_cycles}
\end{figure}

\begin{figure}[thbp]
        \centering
        \includegraphics[width=\linewidth]{./fig/logr64_cycles.png}
    \caption{Native and TeraHeap Spark CPU cycles under 8 GB DRAM per core running Logistic Regression.}
                \label{fig:logr64_cycles}

        \includegraphics[width=\linewidth]{./fig/cc64_cycles.png}
    \caption{Native and TeraHeap Spark CPU cycles under 8 GB DRAM per core running Connected Component.}
                \label{fig:cc64_cycles}
\end{figure}

\begin{figure}[thbp]
        \centering
        \includegraphics[width=\linewidth]{./fig/g_pr128_cycles.png}
    \caption{Native and TeraHeap Giraph CPU cycles under 16 GB DRAM per core running Page Rank.}
                \label{fig:g_pr128_cycles}

        \includegraphics[width=\linewidth]{./fig/g_cdlp128_cycles.png}
    \caption{Native and TeraHeap Giraph CPU cycles under 16 GB DRAM per core running Community Detection Label Propagation.}
                \label{fig:g_cdlp128_cycles}
\end{figure}

\iffalse
\begin{figure}[thbp]
	\centering
        \includegraphics[width=\linewidth]{./fig/CC_64_THR.png}
    \caption{Native and TeraHeap Spark average throughput
        as the number of instances increases under 8 GB DRAM per core running Connected Component.}
		\label{fig:cc_64_thr}
        \iffalse
	\includegraphics[width=\linewidth]{./fig/LINR_128_THR.png}
    \caption{Native and TeraHeap Spark average throughput
        as the number of instances increases under 8 GB DRAM per core running Linear Regression.}
        \label{fig:linr_128_thr}
	\fi
\end{figure}
\fi

\begin{figure}[thbp]
        \centering
        \includegraphics[width=\linewidth]{./fig/PR_64_USR.png}
    \caption{Native and TeraHeap Spark average user CPU utilization
        as the number of instances increases under 8 GB DRAM per core running Page Rank.}
                \label{fig:pr_64_usr}

        \includegraphics[width=\linewidth]{./fig/LINR_64_USR.png}
    \caption{Native and TeraHeap Spark average user CPU utilization
        as the number of instances increases under 8 GB DRAM per core running Linear Regression.}
                \label{fig:linr_64_usr}
\end{figure}


\begin{figure}[thbp]
	\iffalse
        \includegraphics[width=\linewidth]{./fig/PR_256_THR.png}
    \caption{Page Rank 256 GB DRAM setup Native and TeraHeap
    throughput as the number of instances increases.Configurations
    starting with N denote a run with Native instances of Spark and
    with T with TeraHeap. H1 is a run with the memory budget
    configured to contain a bigger size for H1 than PageCache and PC
    the opposite. E.g. T2 PC is a run of 2 concurrent TeraHeap
    instances with exactly the same configuration. }
                \label{fig:pr_256_thr}
        \includegraphics[width=\linewidth]{./fig/PR_256_USR.png}
    \caption{Page Rank 256 GB DRAM setup Native and TeraHeap
    User CPU utilization as the number of instances increases.Configurations
    starting with N denote a run with Native instances of Spark and
    with T with TeraHeap. H1 is a run with the memory budget
    configured to contain a bigger size for H1 than PageCache and PC
    the opposite. E.g. T2 PC is a run of 2 concurrent TeraHeap
    instances with exactly the same configuration. }
   \label{fig:pr_256_usr}
		\fi
        \centering
   \includegraphics[width=\linewidth]{./fig/LOGR_64_USR.png}
    \caption{Native and TeraHeap Spark average user CPU utilization
        as the number of instances increases under 8 GB DRAM per core running Logistic Regression.}
           \label{fig:logr_64_usr}
	\includegraphics[width=\linewidth]{./fig/CC_64_USR.png}
    \caption{Native and TeraHeap Spark average user CPU utilization
        as the number of instances increases under 8 GB DRAM per core running Connected Component.}
        \label{fig:cc_64_usr}
	\iffalse
        \includegraphics[width=\linewidth]{./fig/LINR_128_USR.png}
    \caption{Native and TeraHeap Spark average throughput
        as the number of instances increases under 8 GB DRAM per core running Linear Regression.}
        \label{fig:linr_128_usr}
	\fi
\end{figure}

\begin{figure}[thbp]
	\centering
        \includegraphics[width=\linewidth]{./fig/G_PR_128_USR.png}
    \caption{Native and TeraHeap Giraph average user CPU utilization
        as the number of instances increases under 16 GB DRAM per core running Page Rank.}
        \label{fig:g_pr128_usr}
        \includegraphics[width=\linewidth]{./fig/G_CDLP_128_USR.png}
    \caption{Native and TeraHeap Giraph average user CPU utilization
        as the number of instances increases under 16 GB DRAM per core running Page Rank.}
        \label{fig:g_cdlp128_usr}
\end{figure}
\iffalse
\begin{table}[thbp]
  \centering
  \caption{Range of increment between single and co-located \# of instances and corresponding range of increment factor of user CPU utilization}
  \label{tab:user_factors}
  \begin{tabular}{|c|c|}
    \hline
    \textbf{Incr. in # instances} & \textbf{Incr. Factor} \\
    \hline
    Native Spark 1 to 2  & 1.5x-2.5x \\
    Native Spark 1 to 4 & 2.5x \\
    TH Spark 1 to 2 & 2x-3x \\
    TH Spark 1 to 4 & 2x-3x \\
    Native Giraph 1 to 2 & 2x \\
    TH Giraph 1 to 2 & 2x-2.5x \\
    TH Giraph 1 to 4 & 2.5x-3x \\
    \hline
  \end{tabular}
\end{table}
\fi

The main goal for co-locating tasks is to increase the CPU utilization and achieve better
throughput. In this section, we examine if the CPU utilization translates to better application throughput.
CPU utilization is split to 2 parts. 
User utilization includes all CPU cycles that were executed in user-space threads.
It includes GC cycles, S/D cycles and cycles for mutator tasks except I/O.
System utilization includes all CPU cycles that were executed in kernel-space threads.
This includes I/O carried out by GC (TeraHeap) and mutator I/O.
Therefore, we have to focus to User utilization, which includes the effective CPU cycles executed by the application.
We look at the CPU cycles performed by each configuration and compare it with user and total CPU utilization and then come to our conlusion.
CPU cycles are calculated using the formula (total number of cores * cpu frequency * execution time of slowest instance * cpu utlization achieved by all instances).

In the figures \ref{fig:pr32_cycles}, \ref{fig:linr32_cycles}, \ref{fig:logr32_cycles} and \ref{fig:cc32_cycles}, we look at the CPU cycles under 4 GB memory per core for Spark. We see that TH Spark executes in less CPU cycles (56\% for LinR,55\% for LogR and 16\% for CC) except for PageRank, where Native executes in less cycles by 11\%. In the same time, it has increased CPU utilization compared to Native Spark by 40, 4, 13 and 7 \% accordingly.
This means that reducing GC and S/D leads to more effective CPU utilization for all workloads except PageRank. For PageRank, TH executes in more cycles thus we cannot be sure about the benefit.
In the figures \ref{fig:pr64_cycles}, \ref{fig:linr64_cycles}, \ref{fig:logr64_cycles} and \ref{fig:cc64_cycles}, we look at the CPU cycles under 8 GB memory per core for Spark. For PR, TH Spark executes in less CPU cycles (6\% for T2 H1, 14\% for T2 PC, 25\% for T4 H1, 21\% for T4 PC).
For LinR, TH Spark executes in less CPU cycles (23\% for T2 H1, 24\% for T2 PC, 58\% for T4 H1, 59\% for T4 PC).
For LogR, TH Spark executes in less CPU cycles (48\% for T2 H1, 49\% for T2 PC, 58\% for T4 H1, 53\% for T4 PC).
For PR, TH Spark executes in less CPU cycles for 4 co-located instances (22\% for T4 H1, 21\% for T4 PC), while Native Spark executes in less
CPU cycles for 2 co-located instances (7\% against both T2 H1 and T2 PC).
This means that reducing GC and S/D leads to more effective CPU utilization for all workloads for 2 and 4 co-located instances except for CC with 2 co-located instances.
In the figures \ref{fig:g_pr128_cycles} and \ref{fig:g_cdlp128_cycles}, we look at the CPU cycles under 16 GB memory per core for Giraph. We see that TH Giraph executes in more CPU cycles except for T2 PC in PR with speedup in cycles by 14\%.
This means that reducing GC for Giraph does not necessarily lead to more effective CPU utilization.

If we look at the figures \ref{fig:pr_64_usr}, \ref{fig:linr_64_usr}, \ref{fig:logr_64_usr}, \ref{fig:cc_64_usr}, \ref{fig:g_pr128_usr} and \ref{fig:g_cdlp128_usr}, we witness User utilization for 8 GB memory per core for Spark and 16 GB memory per core for Giraph. TH has more User utilization in all scenarios.
We also include the total CPU utilization (User+System) in \ref{fig:pr_64_util}, \ref{fig:linr_64_util}, \ref{fig:logr_64_util}, \ref{fig:cc_64_util}, \ref{fig:g_pr_128_util} and \ref{fig:g_cdlp_128_util}.
For 4 GB memory per core in Spark and for 8 GB memory per core for Giraph, we do not include user utilization as the number of instances increases, since we cannot run more than 2 instances, especially for Giraph, where Native is not able to run at all. For Spark, TH increases User and and total CPU utilization accordingly to 8 and 16 GB memory per core.
By combining cycles and user utilization, we come to the conclusion that, since TH has increased User utilization in all scenarions, in the ones, where it executes in less CPU cycles it has more effective CPU utilization. That is because of reduced GC and S/D. In the scenarios where it executes in more cycles we cannot say for sure, despite TH having more average throughput. However, for Giraph, we see that decreasing GC and S/D, allows us to run more instances in the server, because TH needs less memory per instance. In terms of choosing what is best for TH, H1 or PC, we see from the CPU cycles that for Spark there are no clear benefits for any side. For Giraph, in \ref{fig:g_pr128_cycles} we see that with 4 instances PC executes in less cycles, but the execution time is the same and CPU utilization is more for TH H1 so the benefit is not clear.
To conclude for Native Spark and Giraph, we see in most scenarios that the increment in CPU utilization is not useful work, but more GC and S/D since the memory for each instance decreases as the number of co-located instances increase.

\subsection{What
happens with monetary cost across different cloud platforms?}

\begin{table}[t!]
  \centering
  \caption{Hourly costs for EC2, GCP and AZ=Azure Cloud}
  \label{tab:cost_table}
  \begin{tabular}{|c|c|c|c|}
    \hline
	  \textbf{Provider} & \textbf{DRAM (GB)} & \textbf{Cores #} & \textbf{Hourly cost (\$)} \\
    \hline
	  EC2 & 128 & 8 & 0.67  \\
	  EC2 & 64 & 8 & 0.4 \\
	  EC2 & 32 & 8 & 0.27 \\
	  GCP & 128 & 8 & -- \\
	  GCP & 64 & 8 & 0.36 \\
	  GCP & 32 & 8 & 0.27 \\
	  AZ & 128 & 8 & 1.05 \\
	  AZ & 64 & 8 & 0.48 \\
	  AZ & 32 & 8 & 0.33 \\ 
	  \hline
  \end{tabular}
\end{table}


Tables \ref{tab:cost_table} shows hourly cost for each machine configuration in 
Amazon Web Services Cloud (EC2), GCP (Google Cloud Platform) and Microsoft Azure costs. 
We witness that Amazon and Google providers offer a similar cost for identical machines to our server.
Azure is more expensive, especially for the 16 GB memory per core machine, which is 36\% more expensive than EC2's.
Google does not offer a 16 GB memory per core machine.
Taking into account that we have an hourly cost and that we have an estimation,
reducing GC and S/D achieves benefits of up to 50\% for running co-located workloads in these clouds. The calculations are very simple so we skip them. We multiple hourly cost
by number of hours needed to execute each experiment until all instances finish execution. The conclusion is that reducing GC and S/D makes a huge difference in the execution time and therefore running with TeraHeap decreases the hours needed to rent the machines.


